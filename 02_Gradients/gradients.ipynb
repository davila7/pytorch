{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients \n",
    "\n",
    "In this section, we are going to learn about the automatic computation of gradients in PyTorch, and how to use them for parameter optimization in machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Gradient in pytorch?\n",
    "\n",
    "A gradient in PyTorch is a vector of partial derivatives of a function with respect to its input variables. It is used to calculate the direction and magnitude of the steepest ascent or descent of a function at a particular point. \n",
    "\n",
    "In deep learning, gradients are used to update the parameters of a neural network during the training process, by backpropagating the error and adjusting the weights and biases accordingly. \n",
    "\n",
    "PyTorch provides automatic differentiation, which allows for efficient computation of gradients without having to manually define and calculate them. This makes it easier to build and train complex neural networks in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor and tell PyTorch that we want to compute the gradient\n",
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# Define a function\n",
    "y = x**2\n",
    "\n",
    "# Compute the gradient\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient\n",
    "print(x.grad)   # Output: tensor([6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7157], requires_grad=True) tensor([1.4730], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "X = torch.tensor([0.5, 0.9, 1.4, 1.8], requires_grad=True)\n",
    "Y = torch.tensor([2.0, 3.8, 5.0, 7.2], requires_grad=True)\n",
    "\n",
    "# Initialize parameters\n",
    "a = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "for i in range(100):\n",
    "    # Make a prediction\n",
    "    predictions = a * X + b\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = torch.mean((predictions - Y)**2)\n",
    "    \n",
    "    # Compute the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters using the gradients\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        \n",
    "    # Zero the gradients\n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "print(a, b)  # Output: optimized parameters a and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "\n",
    "# Define a function\n",
    "y = torch.sum(x ** 2)\n",
    "\n",
    "# Compute the gradient\n",
    "y.backward()\n",
    "\n",
    "# Show the gradient\n",
    "print(x.grad)   # Output: tensor([2., 4., 6.])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
